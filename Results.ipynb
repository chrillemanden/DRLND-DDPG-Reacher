{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion() # Turn on interactive mode on plots\n",
    "\n",
    "# PyTorch imports\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the environment\n",
    "\n",
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='C:/Users/chris/git/deep-reinforcement-learning/p2_continuous-control/Reacher_Windows_x86_64/Reacher_Windows_x86_64/Reacher.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "#print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "#print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "#print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "#print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto load changes in the imported files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_hidden_layers = [50, 50]\n",
    "critic_hidden_layers = [50, 50]\n",
    "agent1 = Agent(state_size, action_size, num_agents, 0, actor_hidden_layers, critic_hidden_layers, use_batch_norm=True, use_noise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(agent, num_agents, n_episodes=1000, max_steps=1000):\n",
    "    scores = []\n",
    "    \n",
    "    scores_window_100 = deque(maxlen=100)\n",
    "    scores_window_40 = deque(maxlen=40)\n",
    "    \n",
    "    for episode in range(1, n_episodes+1):\n",
    "        \n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        score = np.zeros(num_agents)\n",
    "        agent.reset()\n",
    "        \n",
    "        for t in range(max_steps):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            score += rewards\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "\n",
    "            \n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break\n",
    "                \n",
    "        scores_window_100.append(np.mean(score))\n",
    "        scores_window_40.append(score)\n",
    "        scores.append(np.mean(score))        \n",
    "                \n",
    "        if episode % (40 / 20) == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_window_40)))\n",
    "        \n",
    "        if np.mean(scores_window_100)>=30.0:\n",
    "            # Agent has reached target average score. Ending training\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(episode-100, np.mean(scores_window_100)))\n",
    "            torch.save(agent.actor_local.state_dict(), 'actor_model2.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'critic_model2.pth')\n",
    "            break\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2\tAverage Score: 0.95\n",
      "Episode 4\tAverage Score: 0.77\n",
      "Episode 6\tAverage Score: 0.72\n",
      "Episode 8\tAverage Score: 0.71\n",
      "Episode 10\tAverage Score: 0.67\n",
      "Episode 12\tAverage Score: 0.62\n",
      "Episode 14\tAverage Score: 0.56\n",
      "Episode 16\tAverage Score: 0.58\n",
      "Episode 18\tAverage Score: 0.66\n",
      "Episode 20\tAverage Score: 0.75\n",
      "Episode 22\tAverage Score: 0.87\n",
      "Episode 24\tAverage Score: 0.95\n",
      "Episode 26\tAverage Score: 0.98\n",
      "Episode 28\tAverage Score: 1.04\n",
      "Episode 30\tAverage Score: 1.08\n",
      "Episode 32\tAverage Score: 1.14\n",
      "Episode 34\tAverage Score: 1.21\n",
      "Episode 36\tAverage Score: 1.34\n",
      "Episode 38\tAverage Score: 1.53\n",
      "Episode 40\tAverage Score: 1.72\n",
      "Episode 42\tAverage Score: 1.96\n",
      "Episode 44\tAverage Score: 2.25\n",
      "Episode 46\tAverage Score: 2.59\n",
      "Episode 48\tAverage Score: 2.96\n",
      "Episode 50\tAverage Score: 3.45\n",
      "Episode 52\tAverage Score: 4.00\n",
      "Episode 54\tAverage Score: 4.69\n",
      "Episode 56\tAverage Score: 5.41\n",
      "Episode 58\tAverage Score: 6.13\n",
      "Episode 60\tAverage Score: 6.89\n",
      "Episode 62\tAverage Score: 7.74\n",
      "Episode 64\tAverage Score: 8.70\n",
      "Episode 66\tAverage Score: 9.68\n",
      "Episode 68\tAverage Score: 10.71\n",
      "Episode 70\tAverage Score: 11.77\n",
      "Episode 72\tAverage Score: 13.06\n",
      "Episode 74\tAverage Score: 14.33\n",
      "Episode 76\tAverage Score: 15.57\n",
      "Episode 78\tAverage Score: 16.88\n",
      "Episode 80\tAverage Score: 18.23\n",
      "Episode 82\tAverage Score: 19.60\n",
      "Episode 84\tAverage Score: 21.01\n",
      "Episode 86\tAverage Score: 22.40\n",
      "Episode 88\tAverage Score: 23.80\n",
      "Episode 90\tAverage Score: 25.05\n",
      "Episode 92\tAverage Score: 26.28\n",
      "Episode 94\tAverage Score: 27.31\n",
      "Episode 96\tAverage Score: 28.38\n",
      "Episode 98\tAverage Score: 29.37\n",
      "Episode 100\tAverage Score: 30.30\n",
      "Episode 102\tAverage Score: 31.15\n",
      "Episode 104\tAverage Score: 31.88\n",
      "Episode 106\tAverage Score: 32.59\n",
      "Episode 108\tAverage Score: 33.24\n",
      "Episode 110\tAverage Score: 33.86\n",
      "Episode 112\tAverage Score: 34.20\n",
      "Episode 114\tAverage Score: 34.57\n",
      "Episode 116\tAverage Score: 34.90\n",
      "Episode 118\tAverage Score: 35.16\n",
      "Episode 120\tAverage Score: 35.26\n",
      "Episode 122\tAverage Score: 35.27\n",
      "Episode 124\tAverage Score: 35.21\n",
      "Episode 126\tAverage Score: 35.17\n",
      "Episode 128\tAverage Score: 35.18\n",
      "Episode 130\tAverage Score: 35.18\n",
      "Episode 132\tAverage Score: 35.11\n",
      "Episode 134\tAverage Score: 35.14\n",
      "Episode 136\tAverage Score: 35.07\n",
      "Episode 138\tAverage Score: 34.99\n",
      "Episode 140\tAverage Score: 34.93\n",
      "Episode 142\tAverage Score: 34.90\n",
      "Episode 144\tAverage Score: 34.83\n",
      "Episode 146\tAverage Score: 34.75\n",
      "\n",
      "Environment solved in 47 episodes!\tAverage Score: 30.26\n"
     ]
    }
   ],
   "source": [
    "scores1 = ddpg(agent1, num_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "Scores_plot = plt.figure()\n",
    "ax = Scores_plot.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores1)), scores1)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "\n",
    "#plt.savefig(\"Scores_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scores1.txt', 'w') as f:\n",
    "    for item in scores1:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(agent1.actor_local.state_dict(), 'actor_model.pth')\n",
    "#torch.save(agent1.critic_local.state_dict(), 'critic_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 34.5349992280826\n",
      "Score vector\n",
      "[35.11999922 36.82999918 35.8599992  34.47999923 32.18999928 31.5199993\n",
      " 34.06999924 37.76999916 34.37999923 28.79999936 36.83999918 38.69999913\n",
      " 35.08999922 32.53999927 37.96999915 37.59999916 34.28999923 34.46999923\n",
      " 27.06999939 35.10999922]\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "states = env_info.vector_observations            # get the current state\n",
    "score = np.zeros(num_agents)                                      # initialize the score\n",
    "while True:\n",
    "    actions = agent1.act(states)                   # select an action\n",
    "    env_info = env.step(actions)[brain_name]        # send the action to the environment\n",
    "    next_states = env_info.vector_observations   # get the next state\n",
    "    rewards = env_info.rewards                  # get the reward\n",
    "    dones = env_info.local_done                  # see if episode has finished\n",
    "    score += rewards                                # update the score\n",
    "    states = next_states                             # roll over the state to next time step\n",
    "    if np.any(dones):                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(np.mean(score)))\n",
    "print(\"Score vector\")\n",
    "print(score)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2\tAverage Score: 0.04\n",
      "Episode 4\tAverage Score: 0.45\n",
      "Episode 6\tAverage Score: 0.48\n",
      "Episode 8\tAverage Score: 0.47\n",
      "Episode 10\tAverage Score: 0.44\n",
      "Episode 12\tAverage Score: 0.42\n",
      "Episode 14\tAverage Score: 0.42\n",
      "Episode 16\tAverage Score: 0.39\n",
      "Episode 18\tAverage Score: 0.38\n",
      "Episode 20\tAverage Score: 0.37\n",
      "Episode 22\tAverage Score: 0.38\n",
      "Episode 24\tAverage Score: 0.40\n",
      "Episode 26\tAverage Score: 0.44\n",
      "Episode 28\tAverage Score: 0.48\n",
      "Episode 30\tAverage Score: 0.52\n",
      "Episode 32\tAverage Score: 0.53\n",
      "Episode 34\tAverage Score: 0.56\n",
      "Episode 36\tAverage Score: 0.58\n",
      "Episode 38\tAverage Score: 0.61\n",
      "Episode 40\tAverage Score: 0.61\n",
      "Episode 42\tAverage Score: 0.66\n",
      "Episode 44\tAverage Score: 0.67\n",
      "Episode 46\tAverage Score: 0.70\n",
      "Episode 48\tAverage Score: 0.72\n",
      "Episode 50\tAverage Score: 0.75\n",
      "Episode 52\tAverage Score: 0.77\n",
      "Episode 54\tAverage Score: 0.80\n",
      "Episode 56\tAverage Score: 0.85\n",
      "Episode 58\tAverage Score: 0.89\n",
      "Episode 60\tAverage Score: 0.93\n",
      "Episode 62\tAverage Score: 0.95\n",
      "Episode 64\tAverage Score: 0.99\n",
      "Episode 66\tAverage Score: 0.99\n",
      "Episode 68\tAverage Score: 1.00\n",
      "Episode 70\tAverage Score: 1.01\n",
      "Episode 72\tAverage Score: 1.03\n",
      "Episode 74\tAverage Score: 1.04\n",
      "Episode 76\tAverage Score: 1.05\n",
      "Episode 78\tAverage Score: 1.06\n",
      "Episode 80\tAverage Score: 1.08\n",
      "Episode 82\tAverage Score: 1.09\n",
      "Episode 84\tAverage Score: 1.10\n",
      "Episode 86\tAverage Score: 1.11\n",
      "Episode 88\tAverage Score: 1.12\n",
      "Episode 90\tAverage Score: 1.13\n",
      "Episode 92\tAverage Score: 1.16\n",
      "Episode 94\tAverage Score: 1.16\n",
      "Episode 96\tAverage Score: 1.16\n",
      "Episode 98\tAverage Score: 1.17\n",
      "Episode 100\tAverage Score: 1.18\n",
      "Episode 102\tAverage Score: 1.19\n",
      "Episode 104\tAverage Score: 1.19\n",
      "Episode 106\tAverage Score: 1.21\n",
      "Episode 108\tAverage Score: 1.20\n",
      "Episode 110\tAverage Score: 1.19\n",
      "Episode 112\tAverage Score: 1.19\n",
      "Episode 114\tAverage Score: 1.17\n",
      "Episode 116\tAverage Score: 1.17\n",
      "Episode 118\tAverage Score: 1.18\n",
      "Episode 120\tAverage Score: 1.18\n",
      "Episode 122\tAverage Score: 1.18\n",
      "Episode 124\tAverage Score: 1.17\n",
      "Episode 126\tAverage Score: 1.18\n",
      "Episode 128\tAverage Score: 1.18\n",
      "Episode 130\tAverage Score: 1.17\n",
      "Episode 132\tAverage Score: 1.16\n",
      "Episode 134\tAverage Score: 1.15\n",
      "Episode 136\tAverage Score: 1.15\n",
      "Episode 138\tAverage Score: 1.13\n",
      "Episode 140\tAverage Score: 1.12\n",
      "Episode 142\tAverage Score: 1.11\n",
      "Episode 144\tAverage Score: 1.11\n",
      "Episode 146\tAverage Score: 1.11\n",
      "Episode 148\tAverage Score: 1.11\n",
      "Episode 150\tAverage Score: 1.12\n",
      "Episode 152\tAverage Score: 1.11\n",
      "Episode 154\tAverage Score: 1.12\n",
      "Episode 156\tAverage Score: 1.11\n",
      "Episode 158\tAverage Score: 1.09\n",
      "Episode 160\tAverage Score: 1.09\n",
      "Episode 162\tAverage Score: 1.09\n",
      "Episode 164\tAverage Score: 1.09\n",
      "Episode 166\tAverage Score: 1.09\n",
      "Episode 168\tAverage Score: 1.09\n",
      "Episode 170\tAverage Score: 1.09\n",
      "Episode 172\tAverage Score: 1.11\n",
      "Episode 174\tAverage Score: 1.12\n",
      "Episode 176\tAverage Score: 1.13\n",
      "Episode 178\tAverage Score: 1.16\n",
      "Episode 180\tAverage Score: 1.16\n",
      "Episode 182\tAverage Score: 1.17\n",
      "Episode 184\tAverage Score: 1.17\n",
      "Episode 186\tAverage Score: 1.17\n",
      "Episode 188\tAverage Score: 1.17\n",
      "Episode 190\tAverage Score: 1.17\n",
      "Episode 192\tAverage Score: 1.17\n",
      "Episode 194\tAverage Score: 1.18\n",
      "Episode 196\tAverage Score: 1.19\n",
      "Episode 198\tAverage Score: 1.20\n",
      "Episode 200\tAverage Score: 1.19\n",
      "Episode 202\tAverage Score: 1.20\n",
      "Episode 204\tAverage Score: 1.20\n",
      "Episode 206\tAverage Score: 1.20\n",
      "Episode 208\tAverage Score: 1.19\n",
      "Episode 210\tAverage Score: 1.20\n",
      "Episode 212\tAverage Score: 1.19\n"
     ]
    }
   ],
   "source": [
    "agent2 = Agent(state_size, action_size, num_agents, 0, actor_hidden_layers, critic_hidden_layers, use_batch_norm=False, use_noise=False)\n",
    "scores2 = ddpg(agent2, num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising agent from saved weights\n",
    "Run the cell block below to load the pre-trained weights into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=33, out_features=50, bias=True)\n",
       "    (1): Linear(in_features=54, out_features=50, bias=True)\n",
       "  )\n",
       "  (output): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_hidden_layers = [50, 50]\n",
    "critic_hidden_layers = [50, 50]\n",
    "agent_show = Agent(state_size, action_size, num_agents, 0, actor_hidden_layers, critic_hidden_layers, use_batch_norm=True)\n",
    "agent_show.actor_local.load_state_dict(torch.load('actor_model.pth'))\n",
    "agent_show.actor_local.eval()\n",
    "agent_show.critic_local.load_state_dict(torch.load('critic_model.pth'))\n",
    "agent_show.critic_local.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 38.730499134305866\n",
      "Score vector\n",
      "[37.77999916 39.40999912 39.30999912 39.42999912 39.39999912 39.37999912\n",
      " 39.17999912 39.48999912 38.35999914 38.27999914 39.51999912 38.77999913\n",
      " 38.62999914 37.20999917 38.36999914 35.44999921 39.51999912 38.04999915\n",
      " 39.67999911 39.37999912]\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "states = env_info.vector_observations            # get the current state\n",
    "score = np.zeros(num_agents)                                      # initialize the score\n",
    "while True:\n",
    "    actions = agent_show.act(states)                   # select an action\n",
    "    env_info = env.step(actions)[brain_name]        # send the action to the environment\n",
    "    next_states = env_info.vector_observations   # get the next state\n",
    "    rewards = env_info.rewards                  # get the reward\n",
    "    dones = env_info.local_done                  # see if episode has finished\n",
    "    score += rewards                                # update the score\n",
    "    states = next_states                             # roll over the state to next time step\n",
    "    if np.any(dones):                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(np.mean(score)))\n",
    "print(\"Score vector\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
